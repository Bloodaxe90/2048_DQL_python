{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-21T02:58:35.161068Z",
     "start_time": "2024-12-21T02:58:28.914491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from collections import deque\n",
    "from src.utils.inference import *\n",
    "from src.game.dynamics import *\n",
    "import matplotlib.pyplot as plt\n",
    "from src.game.tweny48 import Twenty48\n",
    "\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/v8/_7nzg4ln01d8js37_knftkp40000gp/T/ipykernel_48174/3775736535.py\", line 4, in <module>\n",
      "    from src.utils.inference import *\n",
      "  File \"/Users/Eric/PycharmProjects/2048/src/utils/inference.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T02:58:35.238692Z",
     "start_time": "2024-12-21T02:58:35.226266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_reward(current_state, next_state):\n",
    "    current_max = np.max(current_state)\n",
    "    next_max = np.max(next_state)\n",
    "    reward = (math.log2(next_max) * 0.1)\n",
    "\n",
    "    if next_max == current_max:\n",
    "        reward = 0\n",
    "\n",
    "    reward += len(empty(next_state)) - len(empty(current_state))\n",
    "\n",
    "    return reward"
   ],
   "id": "b3ae39fc7d0d4b89",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T02:58:35.749785Z",
     "start_time": "2024-12-21T02:58:35.733696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_prediction(model: nn.Module, state: np.ndarray, input_neurons, device: str) -> torch.tensor:\n",
    "    model.eval()\n",
    "    state = one_hot_states([state], input_neurons, device)\n",
    "    with torch.inference_mode():\n",
    "        pred = model(state).to(device)\n",
    "    return pred"
   ],
   "id": "b2c35aeb8926f78e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T02:58:35.807937Z",
     "start_time": "2024-12-21T02:58:35.797643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReplayBuffer(deque):\n",
    "\n",
    "    def __init__(self, capacity: int):\n",
    "        super().__init__(maxlen=capacity)\n",
    "\n",
    "    def push(self, transition):\n",
    "        super().append(transition)\n",
    "\n",
    "    def full(self) -> bool:\n",
    "        return len(self) >= self.maxlen\n",
    "\n",
    "    def sample(self, batch_size: int):\n",
    "        return random.sample(self, batch_size)"
   ],
   "id": "cf3c56da2245bde9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T02:58:35.829998Z",
     "start_time": "2024-12-21T02:58:35.822408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def one_hot_states(states: list[np.ndarray], num_classes: int, device: str) -> torch.Tensor:\n",
    "    states_logged = []\n",
    "\n",
    "    for state in states:\n",
    "        state_log = np.where(state == 0, 0, np.log2(state)).astype(np.int64)\n",
    "        states_logged.append(state_log)\n",
    "\n",
    "    states_tensor = torch.Tensor(np.array(states_logged)).long().to(device)\n",
    "\n",
    "    return torch.nn.functional.one_hot(states_tensor, num_classes= num_classes).float().to(device).permute(0, 3, 1, 2)"
   ],
   "id": "37a982d7fac25f73",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T02:58:35.908524Z",
     "start_time": "2024-12-21T02:58:35.883969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        d = out_channels // 4\n",
    "        self.conv1 = nn.Conv2d(in_channels, d, 1, padding='same')\n",
    "        self.conv2 = nn.Conv2d(in_channels, d, 2, padding='same')\n",
    "        self.conv3 = nn.Conv2d(in_channels, d, 3, padding='same')\n",
    "        self.conv4 = nn.Conv2d(in_channels, d, 4, padding='same')\n",
    "\n",
    "    def forward(self, x):\n",
    "        output1 = self.conv1(x)\n",
    "        output2 = self.conv2(x)\n",
    "        output3 = self.conv3(x)\n",
    "        output4 = self.conv4(x)\n",
    "        return torch.cat((output1, output2, output3, output4), dim=1)\n",
    "\n",
    "class DQModelConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, input_neurons: int, hidden_neurons: tuple, output_neurons: int, state_size: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.input_block = nn.Sequential(\n",
    "            ConvBlock(in_channels= input_neurons,\n",
    "                      out_channels= hidden_neurons[0]),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.hidden_blocks = nn.ModuleList()\n",
    "        for i in range(1, len(hidden_neurons)):\n",
    "            self.hidden_blocks.append(nn.Sequential(\n",
    "               ConvBlock(in_channels= hidden_neurons[i-1],\n",
    "                      out_channels= hidden_neurons[i]),\n",
    "               nn.ReLU(),\n",
    "            ))\n",
    "\n",
    "        flattened_in_features = hidden_neurons[-1]*(state_size**2)\n",
    "        flatten_out_features = hidden_neurons[-1] //2\n",
    "        self.output_block = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=flattened_in_features,\n",
    "                      out_features=flatten_out_features),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features=flatten_out_features,\n",
    "                      out_features=output_neurons)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.input_block(x)\n",
    "        for hidden_block in self.hidden_blocks:\n",
    "            x = hidden_block(x)\n",
    "        return self.output_block(x)"
   ],
   "id": "ebe30b1f931815f0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T02:58:35.937560Z",
     "start_time": "2024-12-21T02:58:35.925360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DQModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_neurons: int, hidden_neurons: tuple, output_neurons: int, state_size: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.input_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= input_neurons,\n",
    "                      out_channels= hidden_neurons[0],\n",
    "                      kernel_size=3,\n",
    "                      padding=\"same\"),\n",
    "            nn.BatchNorm2d(hidden_neurons[0]),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.hidden_blocks = nn.ModuleList()\n",
    "        for i in range(1, len(hidden_neurons)):\n",
    "            self.hidden_blocks.append(nn.Sequential(\n",
    "               nn.Conv2d(in_channels= hidden_neurons[i-1],\n",
    "                      out_channels= hidden_neurons[i],\n",
    "                      kernel_size=2,\n",
    "                      padding=\"same\"),\n",
    "               nn.BatchNorm2d(hidden_neurons[i]),\n",
    "               nn.ReLU(),\n",
    "            ))\n",
    "\n",
    "        flattened_in_features = hidden_neurons[-1]*(state_size**2)\n",
    "        flatten_out_features = hidden_neurons[-1] // 2\n",
    "        self.output_block = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=flattened_in_features,\n",
    "                      out_features=flatten_out_features),\n",
    "            nn.BatchNorm1d(flatten_out_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features=flatten_out_features,\n",
    "                      out_features=output_neurons)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.input_block(x)\n",
    "        for hidden_block in self.hidden_blocks:\n",
    "            x = hidden_block(x)\n",
    "        return self.output_block(x)\n"
   ],
   "id": "f745afa9d63e57a8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T02:58:35.976355Z",
     "start_time": "2024-12-21T02:58:35.965753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReplayBuffer(deque):\n",
    "\n",
    "    def __init__(self, capacity: int = 6000):\n",
    "        super().__init__(maxlen=capacity)\n",
    "\n",
    "    def push(self, transition):\n",
    "        super().append(transition)\n",
    "\n",
    "    def full(self) -> bool:\n",
    "        return len(self) >= self.maxlen\n",
    "\n",
    "    def sample(self, batch_size: int):\n",
    "        return random.sample(self, batch_size)\n",
    "\n"
   ],
   "id": "7a3ea84fd3e49c35",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T02:58:36.063773Z",
     "start_time": "2024-12-21T02:58:36.021306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DeepQLearning(Twenty48):\n",
    "\n",
    "    def __init__(self,\n",
    "                 replay_buffer: ReplayBuffer,\n",
    "                 loss_fn: nn.Module,\n",
    "                 hidden_neurons: tuple,\n",
    "                 batch_size: int = 32,\n",
    "                 alpha: float = 0.00005,\n",
    "                 gamma: float = 0.9,\n",
    "                 max_epsilon: float = 0.9,\n",
    "                 min_epsilon: float = 0.01,\n",
    "                 win_val: int = 2048,\n",
    "                 device: str = \"cpu\",\n",
    "                 ):\n",
    "        super().__init__(win_val= win_val)\n",
    "        self.input_neurons: int = int(math.log2(self.win_val) +1)\n",
    "        self.hidden_neurons: tuple = hidden_neurons\n",
    "        self.main_network: DQModelConvBlock = self.create_network().to(device)\n",
    "        self.target_network: DQModelConvBlock = self.create_network().to(device)\n",
    "\n",
    "        self.replay_buffer: ReplayBuffer = replay_buffer\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.main_network.parameters(), lr= alpha)\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.GAMMA = gamma\n",
    "        self.MAX_EPSILON = max_epsilon\n",
    "        self.MIN_EPSILON = min_epsilon\n",
    "        self.epsilon = self.MAX_EPSILON\n",
    "        self.device = device\n",
    "\n",
    "    def train(self,\n",
    "              episodes: int,\n",
    "              main_update_count: int = 100,\n",
    "              main_update_freq: int = 1,\n",
    "              target_update_freq: int = 20\n",
    "              ):\n",
    "        total_scores = []\n",
    "        for episode in range(1, episodes + 1):\n",
    "            steps = 0\n",
    "            total_score = 0\n",
    "            total_loss = 0\n",
    "            #Run through an episode\n",
    "            while self.check_terminal() == \"\":\n",
    "                old_score = np.sum(self.environment)\n",
    "                self.interact()\n",
    "                steps += 1\n",
    "                total_score += np.sum(self.environment) - old_score\n",
    "\n",
    "            #Decay Epsilon\n",
    "            self.decay_epsilon(episode, episodes)\n",
    "\n",
    "            #Update main network\n",
    "            if len(self.replay_buffer) > self.BATCH_SIZE and episode % main_update_freq == 0:\n",
    "                for _ in range(main_update_count):\n",
    "                    total_loss += self.update_main_network()\n",
    "\n",
    "            #Update target network\n",
    "            if episode % target_update_freq == 0:\n",
    "                self.update_target_network()\n",
    "\n",
    "            print(\n",
    "                f\"Episode: {episode}\"\n",
    "                f\" | Highest_Val: {np.max(self.environment)}\"\n",
    "                f\" | Steps: {steps}\"\n",
    "                f\" | Epsilon: {self.epsilon}\"\n",
    "                f\" | Loss: {total_loss / (main_update_count * main_update_freq)}\")\n",
    "\n",
    "            total_scores.append(total_score)\n",
    "            if episode > 50:\n",
    "                average = sum(total_scores[-50:]) / 50\n",
    "                print(f\"Average Score from last 50 episodes: {average}\")\n",
    "\n",
    "            #Reset environment for next episode\n",
    "            self.reset()\n",
    "\n",
    "\n",
    "    def interact(self):\n",
    "        current_state = self.environment.copy()\n",
    "        action = self.get_action()\n",
    "        game_step(self.environment, action)\n",
    "        reward = get_reward(current_state, self.environment)\n",
    "        next_state = self.environment.copy()\n",
    "        done = 1 if self.check_terminal() != \"\" else 0\n",
    "\n",
    "        if self.check_terminal() != \"\" or len(self.replay_buffer) == 0 or not np.array_equal(current_state, next_state):\n",
    "            self.replay_buffer.push((current_state, action, reward, next_state, done))\n",
    "\n",
    "    def update_target_network(self):\n",
    "        #Copy the main network parameters into the target networks\n",
    "        self.target_network.load_state_dict(self.main_network.state_dict())\n",
    "\n",
    "    def update_main_network(self) -> float:\n",
    "        #Fetch Transitions\n",
    "        transitions = self.replay_buffer.sample(self.BATCH_SIZE)\n",
    "\n",
    "        #Format Transitions individual components for training\n",
    "        states = one_hot_states([states[0] for states in transitions], self.input_neurons, self.device)\n",
    "        action_indices = torch.tensor([self.ACTIONS.index(actions[1]) for actions in transitions], device= self.device)\n",
    "        rewards = torch.tensor([rewards[2] for rewards in transitions], dtype= torch.int64, device= self.device)\n",
    "        next_states = one_hot_states([next_states[3] for next_states in transitions], self.input_neurons, self.device)\n",
    "        dones = torch.tensor([dones[4] for dones in transitions], device= self.device)\n",
    "\n",
    "        self.main_network.train()\n",
    "        self.target_network.eval()\n",
    "\n",
    "        #prediction for staten s and action a\n",
    "        current_q_values = self.main_network(states).to(self.device)\n",
    "\n",
    "        #prediction for state s' across actions a'\n",
    "        with torch.inference_mode():\n",
    "            next_q_values = self.target_network(next_states).to(self.device)\n",
    "\n",
    "        #Get the q_value of the action a taken in s\n",
    "        current_q_values = current_q_values.gather(1, action_indices.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        #Get the max next action from a'\n",
    "        max_next_q_values = torch.amax(next_q_values, dim=1)\n",
    "\n",
    "        #Calculate the TD target value\n",
    "        td_target_values = rewards + ((1 - dones) * (self.GAMMA * max_next_q_values))\n",
    "\n",
    "\n",
    "        #Calculate loss with the square of TD error\n",
    "        loss = self.loss_fn(current_q_values, td_target_values)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def get_action(self) -> str:\n",
    "        if random.random() >= self.epsilon:\n",
    "            return self.get_best_action()\n",
    "        else:\n",
    "            return self.get_random_action()\n",
    "\n",
    "    def get_random_action(self) -> str:\n",
    "        #Get a random action after filtering out invalid actions\n",
    "        valid_actions = [action for action in self.ACTIONS if action not in self.get_invalid_actions()]\n",
    "        return random.choice(valid_actions)\n",
    "\n",
    "    def get_best_action(self) -> str:\n",
    "        #Make predication\n",
    "        prediction = make_prediction(self.main_network, self.environment, self.input_neurons, self.device).squeeze()\n",
    "\n",
    "        #Mask invalid actions\n",
    "        invalid_actions_indices = [self.ACTIONS.index(action) for action in self.ACTIONS\n",
    "                                   if action in self.get_invalid_actions()]\n",
    "        masked_prediction = prediction.clone()\n",
    "        masked_prediction[invalid_actions_indices] = -float('inf')\n",
    "        return self.ACTIONS[torch.argmax(masked_prediction).item()]\n",
    "\n",
    "    def get_invalid_actions(self) -> list:\n",
    "        invalid_actions = []\n",
    "        for action in self.ACTIONS:\n",
    "            current_state = self.environment.copy()\n",
    "            game_step(current_state, action)\n",
    "            if np.array_equal(current_state, self.environment):\n",
    "                invalid_actions.append(action)\n",
    "        return invalid_actions\n",
    "\n",
    "    def decay_epsilon(self, episode, max_episodes, power: float= 2):\n",
    "        fraction = episode/max_episodes\n",
    "        self.epsilon = (self.MAX_EPSILON - self.MIN_EPSILON) * ((1 - fraction) ** power) + self.MIN_EPSILON\n",
    "\n",
    "    def create_network(self):\n",
    "        return DQModelConvBlock(input_neurons=self.input_neurons,\n",
    "                     hidden_neurons=self.hidden_neurons,\n",
    "                     output_neurons=len(self.ACTIONS),\n",
    "                     state_size=len(self))\n"
   ],
   "id": "865e2995bf89ec12",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:11:18.466975Z",
     "start_time": "2024-12-21T02:58:50.113046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dql = DeepQLearning(\n",
    "    replay_buffer= ReplayBuffer(capacity=6400),\n",
    "    loss_fn= torch.nn.MSELoss(),\n",
    "    hidden_neurons= (64, 64, 64, 64),\n",
    "    batch_size= 32,\n",
    "    device= device\n",
    ")\n",
    "\n",
    "dql.train(\n",
    "    episodes=200\n",
    ")"
   ],
   "id": "254ab713dfea36ad",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v8/_7nzg4ln01d8js37_knftkp40000gp/T/ipykernel_48174/161119072.py:5: RuntimeWarning: divide by zero encountered in log2\n",
      "  state_log = np.where(state == 0, 0, np.log2(state)).astype(np.int64)\n",
      "/Users/Eric/PycharmProjects/2048/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Convolution.cpp:1041.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 | Highest_Val: 128.0 | Steps: 139 | Epsilon: 0.8911222500000001 | Loss: 0.8255473765730857\n",
      "Episode: 2 | Highest_Val: 32.0 | Steps: 67 | Epsilon: 0.882289 | Loss: 0.7309471082687378\n",
      "Episode: 3 | Highest_Val: 128.0 | Steps: 145 | Epsilon: 0.87350025 | Loss: 0.7545217975974083\n",
      "Episode: 4 | Highest_Val: 128.0 | Steps: 128 | Epsilon: 0.864756 | Loss: 0.7187429744005204\n",
      "Episode: 5 | Highest_Val: 128.0 | Steps: 142 | Epsilon: 0.85605625 | Loss: 0.7081841069459915\n",
      "Episode: 6 | Highest_Val: 128.0 | Steps: 126 | Epsilon: 0.847401 | Loss: 0.711436144709587\n",
      "Episode: 7 | Highest_Val: 128.0 | Steps: 145 | Epsilon: 0.83879025 | Loss: 0.6083241862058639\n",
      "Episode: 8 | Highest_Val: 128.0 | Steps: 165 | Epsilon: 0.830224 | Loss: 0.6673652660846711\n",
      "Episode: 9 | Highest_Val: 128.0 | Steps: 145 | Epsilon: 0.82170225 | Loss: 0.6806801122426986\n",
      "Episode: 10 | Highest_Val: 128.0 | Steps: 152 | Epsilon: 0.813225 | Loss: 0.6612178000807762\n",
      "Episode: 11 | Highest_Val: 128.0 | Steps: 154 | Epsilon: 0.80479225 | Loss: 0.6479515898227691\n",
      "Episode: 12 | Highest_Val: 256.0 | Steps: 203 | Epsilon: 0.796404 | Loss: 0.677974997907877\n",
      "Episode: 13 | Highest_Val: 128.0 | Steps: 138 | Epsilon: 0.7880602500000001 | Loss: 0.6191442739963532\n",
      "Episode: 14 | Highest_Val: 64.0 | Steps: 84 | Epsilon: 0.7797609999999999 | Loss: 0.6312391281127929\n",
      "Episode: 15 | Highest_Val: 256.0 | Steps: 233 | Epsilon: 0.7715062500000001 | Loss: 0.634120300412178\n",
      "Episode: 16 | Highest_Val: 64.0 | Steps: 89 | Epsilon: 0.7632960000000001 | Loss: 0.6323993295431137\n",
      "Episode: 17 | Highest_Val: 64.0 | Steps: 113 | Epsilon: 0.7551302500000001 | Loss: 0.6147516220808029\n",
      "Episode: 18 | Highest_Val: 64.0 | Steps: 92 | Epsilon: 0.747009 | Loss: 0.6363055551052094\n",
      "Episode: 19 | Highest_Val: 128.0 | Steps: 127 | Epsilon: 0.7389322500000001 | Loss: 0.6049611210823059\n",
      "Episode: 20 | Highest_Val: 128.0 | Steps: 115 | Epsilon: 0.7309000000000001 | Loss: 0.6104705177247525\n",
      "Episode: 21 | Highest_Val: 128.0 | Steps: 115 | Epsilon: 0.72291225 | Loss: 0.4840574640035629\n",
      "Episode: 22 | Highest_Val: 64.0 | Steps: 68 | Epsilon: 0.7149690000000001 | Loss: 0.5063819813728333\n",
      "Episode: 23 | Highest_Val: 64.0 | Steps: 80 | Epsilon: 0.7070702500000001 | Loss: 0.45604550302028657\n",
      "Episode: 24 | Highest_Val: 128.0 | Steps: 135 | Epsilon: 0.699216 | Loss: 0.4868273203074932\n",
      "Episode: 25 | Highest_Val: 128.0 | Steps: 119 | Epsilon: 0.69140625 | Loss: 0.44834107846021654\n",
      "Episode: 26 | Highest_Val: 128.0 | Steps: 158 | Epsilon: 0.683641 | Loss: 0.49623283356428144\n",
      "Episode: 27 | Highest_Val: 64.0 | Steps: 95 | Epsilon: 0.67592025 | Loss: 0.46546772062778474\n",
      "Episode: 28 | Highest_Val: 64.0 | Steps: 86 | Epsilon: 0.668244 | Loss: 0.4551877979934216\n",
      "Episode: 29 | Highest_Val: 128.0 | Steps: 142 | Epsilon: 0.6606122499999999 | Loss: 0.4812870380282402\n",
      "Episode: 30 | Highest_Val: 64.0 | Steps: 70 | Epsilon: 0.653025 | Loss: 0.46658158391714094\n",
      "Episode: 31 | Highest_Val: 64.0 | Steps: 86 | Epsilon: 0.6454822499999999 | Loss: 0.4595726938545704\n",
      "Episode: 32 | Highest_Val: 128.0 | Steps: 140 | Epsilon: 0.6379839999999999 | Loss: 0.45427845865488053\n",
      "Episode: 33 | Highest_Val: 64.0 | Steps: 90 | Epsilon: 0.63053025 | Loss: 0.46149286210536955\n",
      "Episode: 34 | Highest_Val: 64.0 | Steps: 106 | Epsilon: 0.6231209999999999 | Loss: 0.44018119558691976\n",
      "Episode: 35 | Highest_Val: 128.0 | Steps: 159 | Epsilon: 0.61575625 | Loss: 0.4522020794451237\n",
      "Episode: 36 | Highest_Val: 128.0 | Steps: 126 | Epsilon: 0.6084360000000001 | Loss: 0.4417062754929066\n",
      "Episode: 37 | Highest_Val: 128.0 | Steps: 152 | Epsilon: 0.60116025 | Loss: 0.44721156626939773\n",
      "Episode: 38 | Highest_Val: 128.0 | Steps: 118 | Epsilon: 0.5939290000000002 | Loss: 0.41376389026641847\n",
      "Episode: 39 | Highest_Val: 64.0 | Steps: 95 | Epsilon: 0.5867422499999999 | Loss: 0.41844128564000127\n",
      "Episode: 40 | Highest_Val: 128.0 | Steps: 153 | Epsilon: 0.5796000000000001 | Loss: 0.443001394867897\n",
      "Episode: 41 | Highest_Val: 128.0 | Steps: 127 | Epsilon: 0.5725022500000001 | Loss: 0.39557898104190825\n",
      "Episode: 42 | Highest_Val: 32.0 | Steps: 70 | Epsilon: 0.5654490000000001 | Loss: 0.3916893991827965\n",
      "Episode: 43 | Highest_Val: 128.0 | Steps: 122 | Epsilon: 0.5584402500000001 | Loss: 0.40561451375484464\n",
      "Episode: 44 | Highest_Val: 128.0 | Steps: 113 | Epsilon: 0.5514760000000001 | Loss: 0.38704949989914894\n",
      "Episode: 45 | Highest_Val: 32.0 | Steps: 56 | Epsilon: 0.5445562500000001 | Loss: 0.41260686591267587\n",
      "Episode: 46 | Highest_Val: 128.0 | Steps: 170 | Epsilon: 0.537681 | Loss: 0.3997496500611305\n",
      "Episode: 47 | Highest_Val: 64.0 | Steps: 93 | Epsilon: 0.53085025 | Loss: 0.3735722157359123\n",
      "Episode: 48 | Highest_Val: 256.0 | Steps: 205 | Epsilon: 0.524064 | Loss: 0.3998603750765324\n",
      "Episode: 49 | Highest_Val: 128.0 | Steps: 154 | Epsilon: 0.51732225 | Loss: 0.3852486683428287\n",
      "Episode: 50 | Highest_Val: 128.0 | Steps: 205 | Epsilon: 0.510625 | Loss: 0.3865103541314602\n",
      "Episode: 51 | Highest_Val: 128.0 | Steps: 152 | Epsilon: 0.50397225 | Loss: 0.372131599932909\n",
      "Average Score from last 50 episodes: 277.48\n",
      "Episode: 52 | Highest_Val: 128.0 | Steps: 131 | Epsilon: 0.497364 | Loss: 0.37702936455607416\n",
      "Average Score from last 50 episodes: 280.32\n",
      "Episode: 53 | Highest_Val: 64.0 | Steps: 92 | Epsilon: 0.49080025 | Loss: 0.3532177202403545\n",
      "Average Score from last 50 episodes: 278.12\n",
      "Episode: 54 | Highest_Val: 128.0 | Steps: 141 | Epsilon: 0.48428099999999996 | Loss: 0.36717629760503767\n",
      "Average Score from last 50 episodes: 278.92\n",
      "Episode: 55 | Highest_Val: 64.0 | Steps: 86 | Epsilon: 0.47780625000000004 | Loss: 0.4005538056790829\n",
      "Average Score from last 50 episodes: 276.44\n",
      "Episode: 56 | Highest_Val: 128.0 | Steps: 179 | Epsilon: 0.471376 | Loss: 0.3736008611321449\n",
      "Average Score from last 50 episodes: 278.36\n",
      "Episode: 57 | Highest_Val: 64.0 | Steps: 78 | Epsilon: 0.46499025000000016 | Loss: 0.3991365168988705\n",
      "Average Score from last 50 episodes: 275.6\n",
      "Episode: 58 | Highest_Val: 256.0 | Steps: 232 | Epsilon: 0.45864900000000003 | Loss: 0.3599162171781063\n",
      "Average Score from last 50 episodes: 278.92\n",
      "Episode: 59 | Highest_Val: 128.0 | Steps: 142 | Epsilon: 0.4523522500000001 | Loss: 0.3619176924228668\n",
      "Average Score from last 50 episodes: 278.72\n",
      "Episode: 60 | Highest_Val: 64.0 | Steps: 94 | Epsilon: 0.44609999999999994 | Loss: 0.3917978726327419\n",
      "Average Score from last 50 episodes: 276.24\n",
      "Episode: 61 | Highest_Val: 64.0 | Steps: 88 | Epsilon: 0.4398922500000001 | Loss: 0.36237341731786726\n",
      "Average Score from last 50 episodes: 273.08\n",
      "Episode: 62 | Highest_Val: 128.0 | Steps: 155 | Epsilon: 0.4337289999999999 | Loss: 0.33459754049777984\n",
      "Average Score from last 50 episodes: 271.28\n",
      "Episode: 63 | Highest_Val: 64.0 | Steps: 99 | Epsilon: 0.4276102500000001 | Loss: 0.35856376245617866\n",
      "Average Score from last 50 episodes: 269.64\n",
      "Episode: 64 | Highest_Val: 256.0 | Steps: 202 | Epsilon: 0.42153599999999997 | Loss: 0.36775396689772605\n",
      "Average Score from last 50 episodes: 274.68\n",
      "Episode: 65 | Highest_Val: 128.0 | Steps: 145 | Epsilon: 0.4155062500000001 | Loss: 0.3573733048141003\n",
      "Average Score from last 50 episodes: 271.12\n",
      "Episode: 66 | Highest_Val: 128.0 | Steps: 149 | Epsilon: 0.4095209999999999 | Loss: 0.3538396427035332\n",
      "Average Score from last 50 episodes: 274.24\n",
      "Episode: 67 | Highest_Val: 128.0 | Steps: 172 | Epsilon: 0.40358025000000003 | Loss: 0.3560707066953182\n",
      "Average Score from last 50 episodes: 276.84\n",
      "Episode: 68 | Highest_Val: 128.0 | Steps: 158 | Epsilon: 0.3976839999999999 | Loss: 0.35774524495005605\n",
      "Average Score from last 50 episodes: 279.88\n",
      "Episode: 69 | Highest_Val: 128.0 | Steps: 122 | Epsilon: 0.39183225000000005 | Loss: 0.34708901479840276\n",
      "Average Score from last 50 episodes: 279.76\n",
      "Episode: 70 | Highest_Val: 128.0 | Steps: 146 | Epsilon: 0.38602500000000006 | Loss: 0.3477156960964203\n",
      "Average Score from last 50 episodes: 281.12\n",
      "Episode: 71 | Highest_Val: 128.0 | Steps: 104 | Epsilon: 0.38026225 | Loss: 0.36104946926236153\n",
      "Average Score from last 50 episodes: 280.6\n",
      "Episode: 72 | Highest_Val: 64.0 | Steps: 102 | Epsilon: 0.37454400000000004 | Loss: 0.3370602954924107\n",
      "Average Score from last 50 episodes: 281.92\n",
      "Episode: 73 | Highest_Val: 64.0 | Steps: 97 | Epsilon: 0.36887025 | Loss: 0.320919094234705\n",
      "Average Score from last 50 episodes: 282.64\n",
      "Episode: 74 | Highest_Val: 128.0 | Steps: 130 | Epsilon: 0.36324100000000004 | Loss: 0.3219323848187923\n",
      "Average Score from last 50 episodes: 282.48\n",
      "Episode: 75 | Highest_Val: 64.0 | Steps: 102 | Epsilon: 0.35765625 | Loss: 0.32436009362339974\n",
      "Average Score from last 50 episodes: 281.6\n",
      "Episode: 76 | Highest_Val: 256.0 | Steps: 207 | Epsilon: 0.35211600000000004 | Loss: 0.3295163404941559\n",
      "Average Score from last 50 episodes: 283.72\n",
      "Episode: 77 | Highest_Val: 64.0 | Steps: 101 | Epsilon: 0.34662025 | Loss: 0.3075384241342545\n",
      "Average Score from last 50 episodes: 284.0\n",
      "Episode: 78 | Highest_Val: 128.0 | Steps: 139 | Epsilon: 0.341169 | Loss: 0.3144023895263672\n",
      "Average Score from last 50 episodes: 286.64\n",
      "Episode: 79 | Highest_Val: 64.0 | Steps: 99 | Epsilon: 0.33576225 | Loss: 0.33080525800585747\n",
      "Average Score from last 50 episodes: 284.92\n",
      "Episode: 80 | Highest_Val: 256.0 | Steps: 220 | Epsilon: 0.3304 | Loss: 0.3296247507631779\n",
      "Average Score from last 50 episodes: 291.32\n",
      "Episode: 81 | Highest_Val: 64.0 | Steps: 102 | Epsilon: 0.32508225 | Loss: 0.33019752517342565\n",
      "Average Score from last 50 episodes: 291.84\n",
      "Episode: 82 | Highest_Val: 64.0 | Steps: 105 | Epsilon: 0.31980900000000007 | Loss: 0.31856549248099325\n",
      "Average Score from last 50 episodes: 289.96\n",
      "Episode: 83 | Highest_Val: 64.0 | Steps: 76 | Epsilon: 0.31458024999999995 | Loss: 0.32580593273043634\n",
      "Average Score from last 50 episodes: 289.32\n",
      "Episode: 84 | Highest_Val: 128.0 | Steps: 112 | Epsilon: 0.3093960000000001 | Loss: 0.31156145364046095\n",
      "Average Score from last 50 episodes: 289.84\n",
      "Episode: 85 | Highest_Val: 256.0 | Steps: 205 | Epsilon: 0.30425624999999995 | Loss: 0.3000290301442146\n",
      "Average Score from last 50 episodes: 292.08\n",
      "Episode: 86 | Highest_Val: 64.0 | Steps: 74 | Epsilon: 0.29916100000000007 | Loss: 0.30025822162628174\n",
      "Average Score from last 50 episodes: 289.96\n",
      "Episode: 87 | Highest_Val: 128.0 | Steps: 149 | Epsilon: 0.29411024999999996 | Loss: 0.29737181425094605\n",
      "Average Score from last 50 episodes: 290.32\n",
      "Episode: 88 | Highest_Val: 256.0 | Steps: 204 | Epsilon: 0.289104 | Loss: 0.29770596340298655\n",
      "Average Score from last 50 episodes: 294.24\n",
      "Episode: 89 | Highest_Val: 64.0 | Steps: 74 | Epsilon: 0.28414225 | Loss: 0.3006400913000107\n",
      "Average Score from last 50 episodes: 293.24\n",
      "Episode: 90 | Highest_Val: 256.0 | Steps: 263 | Epsilon: 0.27922500000000006 | Loss: 0.3022418116033077\n",
      "Average Score from last 50 episodes: 298.08\n",
      "Episode: 91 | Highest_Val: 128.0 | Steps: 151 | Epsilon: 0.27435224999999996 | Loss: 0.2882517196238041\n",
      "Average Score from last 50 episodes: 299.16\n",
      "Episode: 92 | Highest_Val: 32.0 | Steps: 82 | Epsilon: 0.26952400000000004 | Loss: 0.3118975339829922\n",
      "Average Score from last 50 episodes: 299.64\n",
      "Episode: 93 | Highest_Val: 256.0 | Steps: 164 | Epsilon: 0.2647402499999999 | Loss: 0.3070967748761177\n",
      "Average Score from last 50 episodes: 301.4\n",
      "Episode: 94 | Highest_Val: 64.0 | Steps: 82 | Epsilon: 0.26000100000000004 | Loss: 0.3066511142253876\n",
      "Average Score from last 50 episodes: 300.24\n",
      "Episode: 95 | Highest_Val: 64.0 | Steps: 118 | Epsilon: 0.25530625 | Loss: 0.2889992591738701\n",
      "Average Score from last 50 episodes: 303.28\n",
      "Episode: 96 | Highest_Val: 64.0 | Steps: 79 | Epsilon: 0.25065600000000005 | Loss: 0.3107306858897209\n",
      "Average Score from last 50 episodes: 299.24\n",
      "Episode: 97 | Highest_Val: 64.0 | Steps: 127 | Epsilon: 0.24605025 | Loss: 0.29576583586633204\n",
      "Average Score from last 50 episodes: 300.76\n",
      "Episode: 98 | Highest_Val: 256.0 | Steps: 213 | Epsilon: 0.241489 | Loss: 0.28770058050751685\n",
      "Average Score from last 50 episodes: 300.84\n",
      "Episode: 99 | Highest_Val: 64.0 | Steps: 90 | Epsilon: 0.23697225000000002 | Loss: 0.29233077466487883\n",
      "Average Score from last 50 episodes: 298.04\n",
      "Episode: 100 | Highest_Val: 256.0 | Steps: 252 | Epsilon: 0.2325 | Loss: 0.28913562044501306\n",
      "Average Score from last 50 episodes: 300.48\n",
      "Episode: 101 | Highest_Val: 64.0 | Steps: 110 | Epsilon: 0.22807225 | Loss: 0.2860957084596157\n",
      "Average Score from last 50 episodes: 298.84\n",
      "Episode: 102 | Highest_Val: 128.0 | Steps: 143 | Epsilon: 0.223689 | Loss: 0.2743614803999662\n",
      "Average Score from last 50 episodes: 299.0\n",
      "Episode: 103 | Highest_Val: 128.0 | Steps: 150 | Epsilon: 0.21935025 | Loss: 0.2764407642185688\n",
      "Average Score from last 50 episodes: 301.72\n",
      "Episode: 104 | Highest_Val: 64.0 | Steps: 102 | Epsilon: 0.215056 | Loss: 0.28098134845495226\n",
      "Average Score from last 50 episodes: 299.76\n",
      "Episode: 105 | Highest_Val: 128.0 | Steps: 172 | Epsilon: 0.21080625 | Loss: 0.289268506988883\n",
      "Average Score from last 50 episodes: 303.56\n",
      "Episode: 106 | Highest_Val: 64.0 | Steps: 108 | Epsilon: 0.206601 | Loss: 0.27957615301012995\n",
      "Average Score from last 50 episodes: 300.6\n",
      "Episode: 107 | Highest_Val: 128.0 | Steps: 139 | Epsilon: 0.20244025 | Loss: 0.2803167663514614\n",
      "Average Score from last 50 episodes: 303.2\n",
      "Episode: 108 | Highest_Val: 64.0 | Steps: 89 | Epsilon: 0.19832399999999997 | Loss: 0.2707092180848122\n",
      "Average Score from last 50 episodes: 296.6\n",
      "Episode: 109 | Highest_Val: 256.0 | Steps: 206 | Epsilon: 0.19425225 | Loss: 0.27084230750799176\n",
      "Average Score from last 50 episodes: 299.8\n",
      "Episode: 110 | Highest_Val: 128.0 | Steps: 149 | Epsilon: 0.19022499999999998 | Loss: 0.28261671096086505\n",
      "Average Score from last 50 episodes: 302.2\n",
      "Episode: 111 | Highest_Val: 64.0 | Steps: 87 | Epsilon: 0.18624224999999997 | Loss: 0.277102582603693\n",
      "Average Score from last 50 episodes: 302.28\n",
      "Episode: 112 | Highest_Val: 128.0 | Steps: 166 | Epsilon: 0.182304 | Loss: 0.28656013146042825\n",
      "Average Score from last 50 episodes: 302.4\n",
      "Episode: 113 | Highest_Val: 128.0 | Steps: 140 | Epsilon: 0.17841025000000008 | Loss: 0.27666413232684134\n",
      "Average Score from last 50 episodes: 304.4\n",
      "Episode: 114 | Highest_Val: 128.0 | Steps: 152 | Epsilon: 0.17456100000000005 | Loss: 0.274687337577343\n",
      "Average Score from last 50 episodes: 301.88\n",
      "Episode: 115 | Highest_Val: 256.0 | Steps: 164 | Epsilon: 0.17075625000000005 | Loss: 0.27999988839030265\n",
      "Average Score from last 50 episodes: 302.36\n",
      "Episode: 116 | Highest_Val: 128.0 | Steps: 153 | Epsilon: 0.16699600000000003 | Loss: 0.2790967424213886\n",
      "Average Score from last 50 episodes: 302.04\n",
      "Episode: 117 | Highest_Val: 256.0 | Steps: 213 | Epsilon: 0.16328025000000002 | Loss: 0.27669204339385034\n",
      "Average Score from last 50 episodes: 304.12\n",
      "Episode: 118 | Highest_Val: 128.0 | Steps: 146 | Epsilon: 0.15960900000000003 | Loss: 0.26103664204478266\n",
      "Average Score from last 50 episodes: 303.52\n",
      "Episode: 119 | Highest_Val: 256.0 | Steps: 203 | Epsilon: 0.15598225000000004 | Loss: 0.2745531788468361\n",
      "Average Score from last 50 episodes: 307.16\n",
      "Episode: 120 | Highest_Val: 128.0 | Steps: 148 | Epsilon: 0.15240000000000004 | Loss: 0.2785278044641018\n",
      "Average Score from last 50 episodes: 307.36\n",
      "Episode: 121 | Highest_Val: 128.0 | Steps: 140 | Epsilon: 0.14886225000000003 | Loss: 0.2718387104570866\n",
      "Average Score from last 50 episodes: 309.04\n",
      "Episode: 122 | Highest_Val: 256.0 | Steps: 230 | Epsilon: 0.14536900000000003 | Loss: 0.28776758559048177\n",
      "Average Score from last 50 episodes: 314.72\n",
      "Episode: 123 | Highest_Val: 256.0 | Steps: 224 | Epsilon: 0.14192025 | Loss: 0.25902146063745024\n",
      "Average Score from last 50 episodes: 320.44\n",
      "Episode: 124 | Highest_Val: 128.0 | Steps: 163 | Epsilon: 0.138516 | Loss: 0.24685489267110824\n",
      "Average Score from last 50 episodes: 321.96\n",
      "Episode: 125 | Highest_Val: 32.0 | Steps: 60 | Epsilon: 0.13515625 | Loss: 0.25400657936930654\n",
      "Average Score from last 50 episodes: 320.24\n",
      "Episode: 126 | Highest_Val: 128.0 | Steps: 148 | Epsilon: 0.13184099999999999 | Loss: 0.2651640803366899\n",
      "Average Score from last 50 episodes: 317.76\n",
      "Episode: 127 | Highest_Val: 128.0 | Steps: 132 | Epsilon: 0.12857025 | Loss: 0.26359090581536293\n",
      "Average Score from last 50 episodes: 319.24\n",
      "Episode: 128 | Highest_Val: 128.0 | Steps: 142 | Epsilon: 0.125344 | Loss: 0.2757695968449116\n",
      "Average Score from last 50 episodes: 319.32\n",
      "Episode: 129 | Highest_Val: 128.0 | Steps: 151 | Epsilon: 0.12216225 | Loss: 0.2603770910203457\n",
      "Average Score from last 50 episodes: 321.4\n",
      "Episode: 130 | Highest_Val: 256.0 | Steps: 179 | Epsilon: 0.11902499999999998 | Loss: 0.27008139438927176\n",
      "Average Score from last 50 episodes: 319.76\n",
      "Episode: 131 | Highest_Val: 256.0 | Steps: 243 | Epsilon: 0.11593224999999997 | Loss: 0.2621696649491787\n",
      "Average Score from last 50 episodes: 325.84\n",
      "Episode: 132 | Highest_Val: 128.0 | Steps: 146 | Epsilon: 0.11288399999999998 | Loss: 0.25626963064074515\n",
      "Average Score from last 50 episodes: 327.84\n",
      "Episode: 133 | Highest_Val: 256.0 | Steps: 273 | Epsilon: 0.10988024999999997 | Loss: 0.2591091855615377\n",
      "Average Score from last 50 episodes: 336.28\n",
      "Episode: 134 | Highest_Val: 64.0 | Steps: 80 | Epsilon: 0.10692099999999997 | Loss: 0.2566285520046949\n",
      "Average Score from last 50 episodes: 334.48\n",
      "Episode: 135 | Highest_Val: 64.0 | Steps: 78 | Epsilon: 0.10400624999999997 | Loss: 0.2590825378149748\n",
      "Average Score from last 50 episodes: 328.88\n",
      "Episode: 136 | Highest_Val: 128.0 | Steps: 190 | Epsilon: 0.10113599999999996 | Loss: 0.24034571066498756\n",
      "Average Score from last 50 episodes: 333.92\n",
      "Episode: 137 | Highest_Val: 128.0 | Steps: 167 | Epsilon: 0.09831024999999996 | Loss: 0.2682780782878399\n",
      "Average Score from last 50 episodes: 334.16\n",
      "Episode: 138 | Highest_Val: 64.0 | Steps: 68 | Epsilon: 0.09552900000000003 | Loss: 0.2450699469447136\n",
      "Average Score from last 50 episodes: 328.44\n",
      "Episode: 139 | Highest_Val: 128.0 | Steps: 138 | Epsilon: 0.09279225000000002 | Loss: 0.2554077656567097\n",
      "Average Score from last 50 episodes: 331.32\n",
      "Episode: 140 | Highest_Val: 128.0 | Steps: 118 | Epsilon: 0.09010000000000001 | Loss: 0.2464748904854059\n",
      "Average Score from last 50 episodes: 324.92\n",
      "Episode: 141 | Highest_Val: 128.0 | Steps: 152 | Epsilon: 0.08745225000000001 | Loss: 0.24738304659724236\n",
      "Average Score from last 50 episodes: 324.76\n",
      "Episode: 142 | Highest_Val: 256.0 | Steps: 217 | Epsilon: 0.08484900000000002 | Loss: 0.23782146900892256\n",
      "Average Score from last 50 episodes: 330.36\n",
      "Episode: 143 | Highest_Val: 128.0 | Steps: 125 | Epsilon: 0.08229025000000001 | Loss: 0.24445088289678096\n",
      "Average Score from last 50 episodes: 328.72\n",
      "Episode: 144 | Highest_Val: 128.0 | Steps: 154 | Epsilon: 0.079776 | Loss: 0.22977519549429418\n",
      "Average Score from last 50 episodes: 331.76\n",
      "Episode: 145 | Highest_Val: 128.0 | Steps: 168 | Epsilon: 0.07730625 | Loss: 0.22694281689822673\n",
      "Average Score from last 50 episodes: 333.72\n",
      "Episode: 146 | Highest_Val: 128.0 | Steps: 122 | Epsilon: 0.074881 | Loss: 0.2345298730581999\n",
      "Average Score from last 50 episodes: 335.44\n",
      "Episode: 147 | Highest_Val: 128.0 | Steps: 129 | Epsilon: 0.07250025 | Loss: 0.2210756203532219\n",
      "Average Score from last 50 episodes: 335.4\n",
      "Episode: 148 | Highest_Val: 256.0 | Steps: 237 | Epsilon: 0.070164 | Loss: 0.21536129660904407\n",
      "Average Score from last 50 episodes: 336.6\n",
      "Episode: 149 | Highest_Val: 64.0 | Steps: 107 | Epsilon: 0.06787225 | Loss: 0.2275175440311432\n",
      "Average Score from last 50 episodes: 337.32\n",
      "Episode: 150 | Highest_Val: 128.0 | Steps: 144 | Epsilon: 0.065625 | Loss: 0.23028055585920812\n",
      "Average Score from last 50 episodes: 332.48\n",
      "Episode: 151 | Highest_Val: 256.0 | Steps: 241 | Epsilon: 0.06342225 | Loss: 0.22142056569457055\n",
      "Average Score from last 50 episodes: 337.88\n",
      "Episode: 152 | Highest_Val: 128.0 | Steps: 180 | Epsilon: 0.061264 | Loss: 0.22047123819589615\n",
      "Average Score from last 50 episodes: 339.76\n",
      "Episode: 153 | Highest_Val: 128.0 | Steps: 138 | Epsilon: 0.05915025 | Loss: 0.22987573549151422\n",
      "Average Score from last 50 episodes: 339.0\n",
      "Episode: 154 | Highest_Val: 128.0 | Steps: 155 | Epsilon: 0.05708099999999999 | Loss: 0.2089708763360977\n",
      "Average Score from last 50 episodes: 341.72\n",
      "Episode: 155 | Highest_Val: 128.0 | Steps: 147 | Epsilon: 0.055056249999999994 | Loss: 0.2125571734458208\n",
      "Average Score from last 50 episodes: 340.64\n",
      "Episode: 156 | Highest_Val: 128.0 | Steps: 177 | Epsilon: 0.053076 | Loss: 0.2175226852297783\n",
      "Average Score from last 50 episodes: 343.56\n",
      "Episode: 157 | Highest_Val: 128.0 | Steps: 126 | Epsilon: 0.05114024999999999 | Loss: 0.2284440355747938\n",
      "Average Score from last 50 episodes: 342.92\n",
      "Episode: 158 | Highest_Val: 128.0 | Steps: 122 | Epsilon: 0.04924899999999999 | Loss: 0.20893378287553788\n",
      "Average Score from last 50 episodes: 344.36\n",
      "Episode: 159 | Highest_Val: 64.0 | Steps: 95 | Epsilon: 0.04740224999999999 | Loss: 0.2155422669649124\n",
      "Average Score from last 50 episodes: 339.2\n",
      "Episode: 160 | Highest_Val: 128.0 | Steps: 134 | Epsilon: 0.04559999999999999 | Loss: 0.2018488712608814\n",
      "Average Score from last 50 episodes: 338.52\n",
      "Episode: 161 | Highest_Val: 128.0 | Steps: 157 | Epsilon: 0.043842249999999985 | Loss: 0.21053704723715783\n",
      "Average Score from last 50 episodes: 341.48\n",
      "Episode: 162 | Highest_Val: 64.0 | Steps: 72 | Epsilon: 0.042128999999999986 | Loss: 0.20893360652029513\n",
      "Average Score from last 50 episodes: 337.4\n",
      "Episode: 163 | Highest_Val: 256.0 | Steps: 283 | Epsilon: 0.04046025000000002 | Loss: 0.21786896266043188\n",
      "Average Score from last 50 episodes: 343.4\n",
      "Episode: 164 | Highest_Val: 128.0 | Steps: 122 | Epsilon: 0.038836000000000016 | Loss: 0.21309306524693966\n",
      "Average Score from last 50 episodes: 342.36\n",
      "Episode: 165 | Highest_Val: 128.0 | Steps: 168 | Epsilon: 0.03725625000000002 | Loss: 0.20790323339402675\n",
      "Average Score from last 50 episodes: 342.64\n",
      "Episode: 166 | Highest_Val: 64.0 | Steps: 78 | Epsilon: 0.03572100000000001 | Loss: 0.20711676701903342\n",
      "Average Score from last 50 episodes: 339.36\n",
      "Episode: 167 | Highest_Val: 64.0 | Steps: 102 | Epsilon: 0.03423025000000001 | Loss: 0.19884380705654622\n",
      "Average Score from last 50 episodes: 334.28\n",
      "Episode: 168 | Highest_Val: 128.0 | Steps: 153 | Epsilon: 0.03278400000000001 | Loss: 0.21363627552986145\n",
      "Average Score from last 50 episodes: 334.8\n",
      "Episode: 169 | Highest_Val: 64.0 | Steps: 91 | Epsilon: 0.03138225000000001 | Loss: 0.19718490883708\n",
      "Average Score from last 50 episodes: 329.52\n",
      "Episode: 170 | Highest_Val: 128.0 | Steps: 109 | Epsilon: 0.030025000000000003 | Loss: 0.20527577988803386\n",
      "Average Score from last 50 episodes: 327.88\n",
      "Episode: 171 | Highest_Val: 128.0 | Steps: 140 | Epsilon: 0.02871225000000001 | Loss: 0.20065050162374973\n",
      "Average Score from last 50 episodes: 327.72\n",
      "Episode: 172 | Highest_Val: 128.0 | Steps: 191 | Epsilon: 0.027444000000000003 | Loss: 0.20216216914355756\n",
      "Average Score from last 50 episodes: 325.8\n",
      "Episode: 173 | Highest_Val: 64.0 | Steps: 115 | Epsilon: 0.02622025 | Loss: 0.2112388724833727\n",
      "Average Score from last 50 episodes: 320.72\n",
      "Episode: 174 | Highest_Val: 128.0 | Steps: 144 | Epsilon: 0.025041 | Loss: 0.20550981551408767\n",
      "Average Score from last 50 episodes: 319.8\n",
      "Episode: 175 | Highest_Val: 64.0 | Steps: 84 | Epsilon: 0.02390625 | Loss: 0.19582885041832923\n",
      "Average Score from last 50 episodes: 320.84\n",
      "Episode: 176 | Highest_Val: 64.0 | Steps: 102 | Epsilon: 0.022816 | Loss: 0.19862367033958436\n",
      "Average Score from last 50 episodes: 318.68\n",
      "Episode: 177 | Highest_Val: 64.0 | Steps: 112 | Epsilon: 0.021770249999999998 | Loss: 0.19439025804400445\n",
      "Average Score from last 50 episodes: 317.48\n",
      "Episode: 178 | Highest_Val: 128.0 | Steps: 111 | Epsilon: 0.020769 | Loss: 0.18594302386045455\n",
      "Average Score from last 50 episodes: 316.2\n",
      "Episode: 179 | Highest_Val: 256.0 | Steps: 273 | Epsilon: 0.019812249999999997 | Loss: 0.20848747827112674\n",
      "Average Score from last 50 episodes: 321.96\n",
      "Episode: 180 | Highest_Val: 128.0 | Steps: 138 | Epsilon: 0.018899999999999997 | Loss: 0.1975610239058733\n",
      "Average Score from last 50 episodes: 320.28\n",
      "Episode: 181 | Highest_Val: 256.0 | Steps: 223 | Epsilon: 0.018032249999999996 | Loss: 0.2088486734032631\n",
      "Average Score from last 50 episodes: 320.08\n",
      "Episode: 182 | Highest_Val: 128.0 | Steps: 159 | Epsilon: 0.017208999999999995 | Loss: 0.20035220764577388\n",
      "Average Score from last 50 episodes: 320.64\n",
      "Episode: 183 | Highest_Val: 128.0 | Steps: 139 | Epsilon: 0.016430249999999993 | Loss: 0.20440332755446433\n",
      "Average Score from last 50 episodes: 315.0\n",
      "Episode: 184 | Highest_Val: 256.0 | Steps: 180 | Epsilon: 0.015695999999999995 | Loss: 0.1956116906553507\n",
      "Average Score from last 50 episodes: 319.68\n",
      "Episode: 185 | Highest_Val: 64.0 | Steps: 107 | Epsilon: 0.015006249999999995 | Loss: 0.1931164339184761\n",
      "Average Score from last 50 episodes: 320.84\n",
      "Episode: 186 | Highest_Val: 128.0 | Steps: 135 | Epsilon: 0.014360999999999994 | Loss: 0.20840602584183215\n",
      "Average Score from last 50 episodes: 318.36\n",
      "Episode: 187 | Highest_Val: 128.0 | Steps: 146 | Epsilon: 0.013760249999999995 | Loss: 0.21446064852178096\n",
      "Average Score from last 50 episodes: 317.44\n",
      "Episode: 188 | Highest_Val: 128.0 | Steps: 132 | Epsilon: 0.013204000000000006 | Loss: 0.21359418459236623\n",
      "Average Score from last 50 episodes: 320.08\n",
      "Episode: 189 | Highest_Val: 128.0 | Steps: 166 | Epsilon: 0.012692250000000006 | Loss: 0.20662638708949088\n",
      "Average Score from last 50 episodes: 321.44\n",
      "Episode: 190 | Highest_Val: 128.0 | Steps: 167 | Epsilon: 0.012225000000000003 | Loss: 0.21661825031042098\n",
      "Average Score from last 50 episodes: 324.08\n",
      "Episode: 191 | Highest_Val: 256.0 | Steps: 194 | Epsilon: 0.011802250000000004 | Loss: 0.21450773913413287\n",
      "Average Score from last 50 episodes: 325.88\n",
      "Episode: 192 | Highest_Val: 128.0 | Steps: 147 | Epsilon: 0.011424000000000004 | Loss: 0.2012498314678669\n",
      "Average Score from last 50 episodes: 323.44\n",
      "Episode: 193 | Highest_Val: 64.0 | Steps: 90 | Epsilon: 0.011090250000000003 | Loss: 0.20368506401777267\n",
      "Average Score from last 50 episodes: 321.8\n",
      "Episode: 194 | Highest_Val: 128.0 | Steps: 113 | Epsilon: 0.010801000000000002 | Loss: 0.2020041286945343\n",
      "Average Score from last 50 episodes: 320.16\n",
      "Episode: 195 | Highest_Val: 128.0 | Steps: 182 | Epsilon: 0.010556250000000001 | Loss: 0.2143176033347845\n",
      "Average Score from last 50 episodes: 320.88\n",
      "Episode: 196 | Highest_Val: 128.0 | Steps: 143 | Epsilon: 0.010356 | Loss: 0.19337943360209464\n",
      "Average Score from last 50 episodes: 321.84\n",
      "Episode: 197 | Highest_Val: 64.0 | Steps: 105 | Epsilon: 0.010200250000000001 | Loss: 0.19852186009287834\n",
      "Average Score from last 50 episodes: 320.8\n",
      "Episode: 198 | Highest_Val: 256.0 | Steps: 215 | Epsilon: 0.010089 | Loss: 0.20421127654612065\n",
      "Average Score from last 50 episodes: 320.0\n",
      "Episode: 199 | Highest_Val: 128.0 | Steps: 136 | Epsilon: 0.01002225 | Loss: 0.19584429234266282\n",
      "Average Score from last 50 episodes: 321.28\n",
      "Episode: 200 | Highest_Val: 128.0 | Steps: 138 | Epsilon: 0.01 | Loss: 0.19448409743607045\n",
      "Average Score from last 50 episodes: 320.8\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T12:09:57.070355Z",
     "start_time": "2024-12-21T12:09:57.017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def trail_random_ai(ai, episodes: int) -> dict:\n",
    "    wins = 0\n",
    "    dic = {}\n",
    "    print(\"sum\")\n",
    "    for i in range(1, episodes):\n",
    "        while (result := check_terminal(ai.environment, ai.ACTIONS, ai.win_val)) == \"\":\n",
    "            action = ai.get_random_action()\n",
    "            moved, merge = game_step(ai.environment, action)\n",
    "            if not moved and not merge:\n",
    "                action = ai.get_random_action()\n",
    "                moved, merge = game_step(ai.environment, action)\n",
    "\n",
    "        max_val = np.max(ai.environment)\n",
    "        ai.reset()\n",
    "        wins += 1 if result == \"W\" else 0\n",
    "        if i % (episodes / 10) == 0:\n",
    "            print(i)\n",
    "        dic[max_val] = dic.get(max_val, 0) + 1\n",
    "    return dic"
   ],
   "id": "85af81524f263517",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T12:09:57.923952Z",
     "start_time": "2024-12-21T12:09:57.899380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_graph(results:dict):\n",
    "    tile_values = [float(x) for x in results.keys()]\n",
    "    occurrences = list(results.values())\n",
    "    # Sort data for better visualization\n",
    "    sorted_data = sorted(zip(tile_values, occurrences), key=lambda x: x[0])\n",
    "    sorted_tiles, sorted_occurrences = zip(*sorted_data)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(sorted_tiles, sorted_occurrences, color='skyblue', edgecolor='black')\n",
    "    plt.xlabel(\"Tile Value\", fontsize=12)\n",
    "    plt.ylabel(\"Occurrences\", fontsize=12)\n",
    "    plt.title(\"Tile Occurrences in 2048\", fontsize=14)\n",
    "    plt.xticks(sorted_tiles)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ],
   "id": "e72e0ad5387639cd",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T12:10:10.265209Z",
     "start_time": "2024-12-21T12:10:10.048095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = trail_ai(dql, 400)\n",
    "plot_graph(results)"
   ],
   "id": "7bd5d058f993820",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'check_terminal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtrail_random_ai\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdql\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m400\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m plot_graph(results)\n",
      "Cell \u001B[0;32mIn[14], line 6\u001B[0m, in \u001B[0;36mtrail_random_ai\u001B[0;34m(ai, episodes)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, episodes):\n\u001B[0;32m----> 6\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m (result \u001B[38;5;241m:=\u001B[39m \u001B[43mcheck_terminal\u001B[49m(ai\u001B[38;5;241m.\u001B[39menvironment, ai\u001B[38;5;241m.\u001B[39mACTIONS, ai\u001B[38;5;241m.\u001B[39mwin_val)) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m      7\u001B[0m         action \u001B[38;5;241m=\u001B[39m ai\u001B[38;5;241m.\u001B[39mget_best_action()\n\u001B[1;32m      8\u001B[0m         moved, merge \u001B[38;5;241m=\u001B[39m game_step(ai\u001B[38;5;241m.\u001B[39menvironment, action)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'check_terminal' is not defined"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T23:47:01.136339Z",
     "start_time": "2024-12-19T23:46:12.176980Z"
    }
   },
   "cell_type": "code",
   "source": "plot_graph(trail_random_ai(DQL(), 1000))",
   "id": "35efb3262d30fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "975dabe86fdea077"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
